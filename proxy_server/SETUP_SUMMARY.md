# ğŸš€ Bittensor Audio Processing Proxy Server - Setup Summary

## ğŸ¯ What We've Built

We've successfully created a **complete FastAPI proxy server** with **service-specific endpoints** that integrates seamlessly with your Bittensor audio processing subnet. This server provides:

### âœ¨ **Core Features**
- **Service-Specific REST API endpoints** for transcription, TTS, and summarization
- **Priority-based task queue** with Redis backend
- **Automatic Bittensor integration** - queries miners and evaluates responses
- **Smart scoring system** - combines accuracy (70%) and speed (30%) scores
- **Task lifecycle management** - from submission to completion
- **Retry mechanism** for failed tasks
- **Real-time monitoring** and health checks
- **Input validation** and formatting for each service type

### ğŸ—ï¸ **Architecture Overview**
```
User Request â†’ FastAPI Server â†’ Task Queue â†’ Bittensor Network â†’ Miners
                â†“                    â†“              â†“
            Response â† Result â† Validator â† Miner Responses
```

## ğŸ“ **File Structure**
```
proxy_server/
â”œâ”€â”€ main.py                 # FastAPI application with service-specific endpoints
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ task_queue.py          # Task queue management with Redis
â”œâ”€â”€ bittensor_client.py    # Bittensor network integration
â”œâ”€â”€ start_server.py        # Server startup script
â”œâ”€â”€ start.sh               # Bash startup script
â”œâ”€â”€ test_proxy.py          # Comprehensive test suite
â”œâ”€â”€ example_usage.py       # Example usage demonstrations
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Dockerfile            # Docker containerization
â”œâ”€â”€ docker-compose.yml    # Docker services setup
â”œâ”€â”€ README.md             # Comprehensive documentation
â””â”€â”€ SETUP_SUMMARY.md      # This file
```

## ğŸš€ **Quick Start Options**

### **Option 1: Direct Python (Recommended for Development)**
```bash
cd proxy_server
./start.sh
```

### **Option 2: Docker Compose (Recommended for Production)**
```bash
cd proxy_server
docker-compose up -d
```

### **Option 3: Manual Setup**
```bash
cd proxy_server
pip install -r requirements.txt
python start_server.py
```

## ğŸ”§ **Prerequisites**

1. **Redis Server** - for task queue management
2. **Python 3.8+** - for running the server
3. **Bittensor Wallet** - configured with your credentials
4. **Network Access** - to Bittensor network (finney/testnet)

## ğŸŒ **Service-Specific API Endpoints**

### **1. Audio Transcription** - `POST /api/v1/transcription`
- **Input**: Audio file upload + source language
- **Format**: Multipart form data
- **Validation**: File size limit (50MB), supported languages
- **Processing**: Audio â†’ Text via Bittensor miners
- **Output**: Transcribed text with accuracy/speed scores

### **2. Text-to-Speech** - `POST /api/v1/tts`
- **Input**: Text + source language
- **Format**: JSON payload
- **Validation**: Text length (max 10K chars), supported languages
- **Processing**: Text â†’ Audio via Bittensor miners
- **Output**: Audio data with accuracy/speed scores

### **3. Text Summarization** - `POST /api/v1/summarization`
- **Input**: Long text + source language
- **Format**: JSON payload
- **Validation**: Text length (50-50K chars), supported languages
- **Processing**: Long text â†’ Summary via Bittensor miners
- **Output**: Summarized text with accuracy/speed scores

### **4. Task Management**
- **Status Check**: `GET /api/v1/tasks/{id}`
- **List Tasks**: `GET /api/v1/tasks`
- **Health Check**: `GET /api/v1/health`

## ğŸ“Š **How It Works**

### **1. Task Submission**
- User submits task via **service-specific endpoint**
- **Input validation** ensures proper format and requirements
- Task is added to **priority queue** in Redis
- Returns task ID for tracking

### **2. Task Processing**
- Background worker picks up tasks from queue
- Creates **Bittensor synapse** with proper formatting
- Queries available miners through your subnet
- Sends requests to top miners (configurable limit)

### **3. Response Evaluation**
- **Validator pipeline runs locally** for comparison
- Calculates **accuracy scores** for each miner response
- Combines accuracy (70%) and speed (30%) scores
- Selects **best response** based on combined score

### **4. Task Completion**
- Best result is stored and task marked as completed
- User can retrieve result via status endpoint
- Task is dequeued and marked as completed

## ğŸ¯ **Scoring System**

Tasks are evaluated using a weighted scoring system:

- **Accuracy Score (70%)**: Based on comparison with validator pipeline
- **Speed Score (30%)**: Based on processing time
- **Combined Score**: Weighted average of accuracy and speed

## ğŸ”„ **Retry Mechanism**

Failed tasks are automatically retried up to 3 times before being marked as permanently failed.

## ğŸ“ˆ **Monitoring**

### **Queue Statistics**
- Pending tasks count
- Processing tasks count
- Completed tasks count
- Failed tasks count
- Queue size

### **Network Statistics**
- Total miners
- Available miners
- Total stake
- Network connectivity status

## ğŸ§ª **Testing the System**

### **1. Start the Server**
```bash
cd proxy_server
./start.sh
```

### **2. Run Test Suite**
```bash
python test_proxy.py
```

### **3. Run Example Usage**
```bash
python example_usage.py
```

### **4. Manual Testing with curl**
```bash
# Health check
curl http://localhost:8000/api/v1/health

# Submit transcription task
curl -X POST "http://localhost:8000/api/v1/transcription" \
  -F "audio_file=@audio.wav" \
  -F "source_language=en" \
  -F "priority=normal"

# Submit TTS task
curl -X POST "http://localhost:8000/api/v1/tts" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hello world",
    "source_language": "en",
    "priority": "normal"
  }'

# Submit summarization task
curl -X POST "http://localhost:8000/api/v1/summarization" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Long article text...",
    "source_language": "en",
    "priority": "normal"
  }'

# Check task status (replace {task_id} with actual ID)
curl "http://localhost:8000/api/v1/tasks/{task_id}"
```

## âš™ï¸ **Configuration**

### **Environment Variables**
```bash
export ENVIRONMENT=development
export BT_NETUID=49
export BT_NETWORK=finney
export BT_WALLET_NAME=luno
export BT_WALLET_HOTKEY=arusha
export REDIS_HOST=localhost
export REDIS_PORT=6379
```

### **Key Settings in config.py**
- `MAX_CONCURRENT_TASKS`: Maximum tasks processed simultaneously
- `TASK_TIMEOUT`: Timeout for Bittensor requests
- `MAX_MINERS_PER_REQUEST`: Number of miners to query per task
- `ACCURACY_WEIGHT`: Weight for accuracy in scoring (default: 0.7)
- `SPEED_WEIGHT`: Weight for speed in scoring (default: 0.3)

## ğŸ”„ **Task Lifecycle**

1. **PENDING** â†’ Task submitted and queued
2. **PROCESSING** â†’ Task picked up by worker
3. **COMPLETED** â†’ Task processed successfully
4. **FAILED** â†’ Task failed after retries

## ğŸš¨ **Troubleshooting**

### **Common Issues**

1. **Redis Connection Error**
   ```bash
   # Check if Redis is running
   redis-cli ping
   
   # Start Redis if needed
   brew services start redis  # macOS
   sudo systemctl start redis-server  # Linux
   ```

2. **Bittensor Connection Error**
   - Verify wallet configuration
   - Check network connectivity
   - Ensure metagraph sync

3. **Task Processing Errors**
   - Check miner availability
   - Verify input data format
   - Review server logs

### **Logs**
The server provides detailed logging for:
- Task submission and processing
- Bittensor network communication
- Miner response evaluation
- Error details and stack traces

## ğŸ¯ **Integration with Your Existing System**

This proxy server is designed to work alongside your existing:
- âœ… **Miner** (running on port 8091)
- âœ… **Validator** (running on port 8092)
- âœ… **Bittensor subnet** (netuid 49)

The server acts as a **professional bridge** between external users and your Bittensor network, providing:
- **Service-specific REST API interface** for easy integration
- **Task queuing** for handling multiple requests
- **Automatic miner evaluation** using your existing validator logic
- **Result aggregation** and scoring
- **Proper input formatting** for each service type

## ğŸš€ **Next Steps**

1. **Start the server** using one of the methods above
2. **Test the API** using the test suite or example usage script
3. **Integrate with your applications** using the service-specific endpoints
4. **Monitor performance** using the health check endpoints
5. **Scale as needed** using Docker or production deployment

## ğŸ‰ **What You Now Have**

A **production-ready proxy server** with **service-specific endpoints** that:
- âœ… Integrates seamlessly with your Bittensor subnet
- âœ… Provides **dedicated endpoints** for each service type
- âœ… Handles **proper input validation** and formatting
- âœ… Manages task queuing and processing
- âœ… Automatically evaluates and scores miner responses
- âœ… Includes comprehensive monitoring and health checks
- âœ… Supports Docker deployment
- âœ… Includes full test suite and examples
- âœ… Has detailed documentation

## ğŸŒŸ **Key Benefits of Service-Specific Endpoints**

1. **Clear API Design**: Each service has its own dedicated endpoint
2. **Proper Input Validation**: Service-specific validation rules
3. **Easy Integration**: Developers can use the right endpoint for their needs
4. **Better Error Handling**: Service-specific error messages
5. **Scalable Architecture**: Easy to add new services in the future

Your **audio processing Bittensor subnet** now has a **professional web interface** with **service-specific endpoints** that can handle real-world usage! ğŸš€

## ğŸ“š **API Documentation**

Once the server is running, you can access:
- **Interactive API docs**: `http://localhost:8000/docs`
- **ReDoc documentation**: `http://localhost:8000/redoc`
- **OpenAPI schema**: `http://localhost:8000/openapi.json`
